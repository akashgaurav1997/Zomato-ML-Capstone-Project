{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akashgaurav1997/Zomato-ML-Capstone-Project/blob/main/Zomato_ML_Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Zomato ML Capstone Project\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Akashgaurav Omprakash Chaudhary\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**\n",
        "Zomato is an Indian restaurant aggregator and food delivery start-up founded by Deepinder Goyal and Pankaj Chaddah in 2008. Zomato provides information, menus and user-reviews of restaurants, and also has food delivery options from partner restaurants in select cities. India is quite famous for its diverse multi cuisine available in a large number of restaurants and hotel resorts, which is reminiscent of unity in diversity. Restaurant business in India is always evolving. More Indians are warming up to the idea of eating restaurant food whether by dining outside or getting food delivered. The growing number of restaurants in every state of India has been a motivation to inspect the data to get some insights, interesting facts and figures about the Indian food industry in each city. So, this project focuses on analysing the Zomato restaurant data for Hyderabad a famous city in India.\n",
        "\n",
        "The Project focuses on Customers and Company, we have to analyze the sentiments of the reviews given by the customer in the data and make some useful conclusions in the form of Visualizations. Also, cluster the zomato restaurants into different segments. The data is vizualized as it becomes easy to analyse data at instant. The Analysis also solves some of the business cases that can directly help the customers finding the Best restaurant in their locality and for the company to grow up and work on the fields they are currently lagging in. This could help in clustering the restaurants into segments. Also the data has valuable information around cuisine and costing which can be used in cost vs. benefit analysis Data could be used for sentiment analysis. Also the metadata of reviewers can be used for identifying the critics in the industry.\n",
        "\n",
        "First, we will try to find out some of the problems to be solved through this project and will try to make some conclusions out of it.\n",
        "\n",
        "Second, we will import the data from the drive and then will convert it into dataframe.\n",
        "\n",
        "Third, we will try to understand the variables in the data and their usefullness.\n",
        "\n",
        "Fourth, we will try to clean the data, we will remove any duplicates or any unneccessary rows or columns.\n",
        "\n",
        "Once, data will be ready for further use. We will try to visualize the data with the help of matplotlib and seaborn. We will create some useful charts and graphs. We will create some univariate charts like scatter plot and some multivariate charts like heatmap.\n",
        "\n",
        "Once, charts will be created, we will try to find out if there is any  relationship between those variables and will try to get some useful insights from those charts. We will write some conclusions based on those insights.\n",
        "\n",
        "After visualizing the charts, we will make some hypothesis and then we will test those hypothesis with the help of various statistical analysis.\n",
        "\n",
        "After hyposthesis testing, we will do some feature engineering and data processing task. We will create some Machine Learning models as well. We will try to observe, which model is performing better on learning data as well as on test data.\n",
        "\n",
        "Based on these above works, we will make some conclusions and try to predict if any customer will recommend our platform to someone else or not, if a customer is satisfied with restaurants services or not."
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Problem Statement Here.**\n",
        "\n",
        "* In the restaurant business, it is crucial to provide value-for-money service as well as food to the customers.\n",
        "* Zomato is in the business of delivering food and providing dine-in facilities in their partner restaurants.\n",
        "* It is important for Zomato to keep track of their partner restaurants' performance in order to lead in the business.\n",
        "* As analysts, it is our job to identify restaurants that are performing very well.\n",
        "* We can suggest the names of the partner restaurants to Zomato so that it can recommend the best restaurants to its customers, providing them with a value-for-money experience, and Zomato will gain more business.\n",
        "* By analyzing restaurant performance metrics, we aim to enhance Zomato's offerings and elevate customer satisfaction.\n",
        "* Our insights will empower Zomato to curate personalized dining experiences tailored to individual preferences."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "id": "twWd8icGpj0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Some Common Libraries:\n",
        "import nltk  #(Natural Language Toolkit) For Textual Task like tokenization, stemming, lemmatization, part-of-speech tagging, etc.\n",
        "import sklearn  #(Scikit-learn) For Data Mining and Data Analysis.\n",
        "import numpy as np  #(Numerical Python) For Multi-Dimensional Arrays And Matrices, a wide range of mathematical operations.\n",
        "import pandas as pd  #For Data Structuring, Data Preprocessing, Exploration, and Manipulation in data science and analytics workflows.\n",
        "import seaborn as sns  #For creating attractive and informative Statistical Graphics.\n",
        "import scipy.stats as stats  #(Statistics) For extracting meaningful insights from data, making informed decisions, and drawing conclusions based on evidence and probability.\n",
        "import statsmodels.api as sm  #For Statistical Modeling and Hypothesis Testing.\n",
        "import matplotlib.pyplot as plt  #For creating visualizations such as Plots, Charts, and Graphs.\n",
        "from sklearn.cluster import KMeans  #For clustering data points into a specified number of clusters.\n",
        "from nltk.stem import WordNetLemmatizer  #To transform words into their base or root form, known as lemma.\n",
        "from nltk.tokenize import word_tokenize  #For  splitting a sentence or text into individual words or tokens.\n",
        "from sklearn.metrics import silhouette_score  # To evaluate the quality of clusters formed by clustering algorithms, such as K-means.\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting google drive:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7Evmk-UoTpVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting data to dataframe:\n",
        "df_reviews = pd.read_csv('/content/drive/MyDrive/weekyly_dayfolder/Zomato Restaurant reviews.csv')\n",
        "df_names = pd.read_csv('/content/drive/MyDrive/weekyly_dayfolder/Zomato Restaurant names and Metadata (1).csv')"
      ],
      "metadata": {
        "id": "xgpQTw3vT5a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look:\n",
        "df_reviews.head(5)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look:\n",
        "df_names.head(5)"
      ],
      "metadata": {
        "id": "tI2JsMlcVmg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset names rows & columns count:\n",
        "df_names.shape"
      ],
      "metadata": {
        "id": "i6Sqz-_IWoT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset reviews rows & columns count:\n",
        "df_reviews.shape"
      ],
      "metadata": {
        "id": "VPBmsXnmdmbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding restaurant missing in reviews dataset:\n",
        "\n",
        "# extacting the name of the restaurant from each dataset and making a set of those data.\n",
        "restaurant_set1 = set(df_names['Name'])\n",
        "restaurant_set2 = set(df_reviews['Restaurant'])\n",
        "\n",
        "# Finding restaurant name which is available in df_names but not in df_reviews:\n",
        "missing_restaurant = restaurant_set1 - restaurant_set2\n",
        "\n",
        "# Printing names of missing restaurant:\n",
        "for restaurant in missing_restaurant:\n",
        "  print(restaurant)"
      ],
      "metadata": {
        "id": "7Jx3L9ENxr-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset names non value count:\n",
        "df_names.info()"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset reviews non-value count:\n",
        "df_reviews.info()"
      ],
      "metadata": {
        "id": "p3g5UV28d_2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count:\n",
        "df_names.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "df_names dataset has no duplicate value."
      ],
      "metadata": {
        "id": "cAjTIpLRHH0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count:\n",
        "df_reviews.duplicated().sum()"
      ],
      "metadata": {
        "id": "8FZ7iYLAHPfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "df_reviews has 36 duplicate values, we are going to drop the duplicate values."
      ],
      "metadata": {
        "id": "shRLBwlrHXB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling duplicate values:\n",
        "df_reviews.drop_duplicates()\n",
        "df_reviews"
      ],
      "metadata": {
        "id": "6q5v8YfWHgZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for duplicates after handling duplicate\n",
        "df_reviews.duplicated().sum()"
      ],
      "metadata": {
        "id": "JZNIw1hyIFZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "df_new_reviews dataset has no duplicate values."
      ],
      "metadata": {
        "id": "KByRUDwiIPT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df_names.isna().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collection column has 54 null values and timing column has 1 null values, we are going to handle both cases differently, we are going to impute 'No data' in collections columns, if it will create any issue, and we are going to impute 12 hrs in timing, as majority of restaurant is running for 12 hours and this is only 1 data, but we cannot drop this data as restaurant information might be important."
      ],
      "metadata": {
        "id": "5HvdeSMsJAQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# handling missing values\n",
        "df_names['Collections'] = df_names['Collections'].fillna('No Data')\n",
        "df_names['Timings'] = df_names['Timings'].fillna('12 hrs')"
      ],
      "metadata": {
        "id": "1U7ay1nOI_Sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for missing values after handling missing values\n",
        "df_names.isna().sum()"
      ],
      "metadata": {
        "id": "biDPTD7eKgnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no missing values now in df_names dataset."
      ],
      "metadata": {
        "id": "mCB6agUfKqjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I3tPZ3y6Kqcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking misssing values in df_revies\n",
        "df_reviews.isna().sum()"
      ],
      "metadata": {
        "id": "gsfTAfOJKwKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In dr_reviews dataset there is many columns with missing values, we can impute data for other columns but we cannot guise the name of the reviewer, even though missing of reviewer name won't affect reveiw annalysis of restaurant, but it seems data of other columns of same reviewer is missing, so we will handle it by dropping the null, and will see what effect it made."
      ],
      "metadata": {
        "id": "s1cC05ndLNcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# handling missing values:\n",
        "df_reviews['Reviewer'] = df_reviews['Reviewer'].fillna('unknown')\n",
        "df_reviews['Review'] = df_reviews['Review'].fillna('unknown')\n",
        "df_reviews['Rating'] = df_reviews['Rating'].fillna(0)\n",
        "df_reviews['Metadata'] = df_reviews['Metadata'].fillna('unknown')\n",
        "df_reviews['Time'] = df_reviews['Time'].fillna(0)"
      ],
      "metadata": {
        "id": "9RzxcfMcScIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking missing values after handling the missing values\n",
        "df_reviews.isna().sum()"
      ],
      "metadata": {
        "id": "dCRZRbayMqQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no missing values now in df_reviews dataset."
      ],
      "metadata": {
        "id": "tqKHFw1ZM6wI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing both cleaned dataset\n",
        "df_names.head(5)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_reviews.head(5)"
      ],
      "metadata": {
        "id": "CahBtBsaNPp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here:\n",
        "\n",
        "*df_names Dataset:*\n",
        "\n",
        "* Contains details of restaurants.\n",
        "* Includes columns such as the name of the restaurant, URL link, cost, * collections, cuisines, and restaurant timings.\n",
        "\n",
        "*df_reviews Dataset:*\n",
        "\n",
        "* Contains details of customers and their reviews.\n",
        "* Includes columns such as the restaurant name, reviewer name, review, rating, metadata (number of reviews of the reviewer, followers count), timing of the review, and the number of pictures posted by the reviewer."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns:\n",
        "df_names.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe:\n",
        "df_names.describe()"
      ],
      "metadata": {
        "id": "SCIs0y7wPtsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns:\n",
        "df_reviews.columns"
      ],
      "metadata": {
        "id": "FLo9OaqOQDYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe:\n",
        "df_reviews.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*Answer Here:*\n",
        "*In the df_names dataset, there are six variables of object datatype:*\n",
        "\n",
        "1. Name: Provides names of the restaurants.\n",
        "2. Links: Provides URL links of the restaurants.\n",
        "3. Collections: Provides types of restaurants.\n",
        "4. Cuisines: Provides food variety provided by the restaurants.\n",
        "5. Timings: Provides restaurants' working hours.\n",
        "\n",
        "*In the df_reviews dataset, there are six variables of object datatype and one integer:*\n",
        "\n",
        "1. Restaurant: Provides the name of the restaurant the reviewer visited.\n",
        "2. Reviewer: Provides the name of the reviewer.\n",
        "3. Review: Provides details of the review given by the reviewer.\n",
        "4. Rating: Provides ratings of the restaurant given by the reviewer.\n",
        "5. Metadata: Provides the number of reviews and followers of the reviewer.\n",
        "6. Timing: Provides the review timing given by the reviewer.\n",
        "7. Picture: Provides the number of pictures posted by the reviewer.\""
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#finding unique values using describe method.\n",
        "df_names.describe()"
      ],
      "metadata": {
        "id": "sZrwlM73fYIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finding unique value of df_names dataset using nunique method.\n",
        "unique_counts1 = df_names.nunique()\n",
        "unique_counts1"
      ],
      "metadata": {
        "id": "x7boBk0Ogenc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding unique value of df_reviews dataset.\n",
        "unique_counts = df_reviews.nunique()\n",
        "unique_counts"
      ],
      "metadata": {
        "id": "e7E_bSt6fyZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have two approches to find unique values, second is direct approach, we can get all the unique values of each variable now."
      ],
      "metadata": {
        "id": "GOzH_eqdfhr7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "merged_df = pd.merge(df_reviews, df_names, left_on='Restaurant', right_on='Name', how='inner')\n",
        "merged_df.head(5)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding non null value:\n",
        "merged_df.info()"
      ],
      "metadata": {
        "id": "qB9vq5mHiYYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting data type of Rating and Cost to integer:\n",
        "\n",
        "merged_df['Cost'] = merged_df['Cost'].str.replace(',', '').astype(int)\n"
      ],
      "metadata": {
        "id": "mC1sD2mDGpKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting data type of Rating to float and handling string inputs:\n",
        "merged_df['Rating'] = pd.to_numeric(merged_df['Rating'], errors='coerce').fillna(0)\n"
      ],
      "metadata": {
        "id": "KNXANjFlKr1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding non-null value after handling string values and converting datatypes:\n",
        "merged_df.info()"
      ],
      "metadata": {
        "id": "UrUaxGG3JSi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Droping name column as restaurant column has name of the restaurant:\n",
        "merged_df.drop('Name', axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "5114DGqRioLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing first 5 rows of dataset after droping name column:\n",
        "merged_df.head(5)"
      ],
      "metadata": {
        "id": "XxAY4kf0jC-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the 'Cuisines' column by commas and expand them into separate rows\n",
        "cuisines_expanded = merged_df['Cuisines'].str.split(', ', expand=True).stack()\n",
        "\n",
        "# Count the occurrences of each cuisine\n",
        "food_variety_counts = cuisines_expanded.value_counts()\n",
        "\n",
        "# Get the top 5 most frequent food varieties\n",
        "top_5_food_varieties = food_variety_counts.head(5)\n",
        "\n",
        "print(top_5_food_varieties)\n"
      ],
      "metadata": {
        "id": "wGr1JbDqlVYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top 10 reviewer\n",
        "reviewer_count = merged_df['Reviewer'].value_counts()\n",
        "reviewer_count.head(10)"
      ],
      "metadata": {
        "id": "NwB8M8EDtD24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 restaurant with most appearance\n",
        "restaurant_count = merged_df['Restaurant'].value_counts()\n",
        "restaurant_count.head(20)"
      ],
      "metadata": {
        "id": "i_7fruKsurCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Answer Here.#\n",
        "*We have two dataset in this project:*\n",
        "1. df_names with restaurant details.\n",
        "2. df_reviews with reviewer details.\n",
        "2. df_names has 105 rows and 6 columns.\n",
        "3. df_reviews has 10000 rows and 7 columns.\n",
        "\n",
        "*We found out that there are 5 restaurant name not availabe in reviews dataset:*\n",
        "* Angaara Counts 3\n",
        "* IndiBlaze\n",
        "* Sweet Basket\n",
        "* Wich Please\n",
        "* Republic Of Noodles - Lemon Tree Hotel\n",
        "\n",
        "*We found some missing values in df_reviews dataset, the missing values was handled using unknown string and 0.*\n",
        "\n",
        "*In df_names dataset, there was no missing value.*\n",
        "\n",
        "*We tried to find unique values in both dataset.*\n",
        "\n",
        "*We have merged both dataset and transferred it to a new variable named merged_df.*\n",
        "\n",
        "*We tried to find out if there is any null value in new dataset, but there is no null value in new dataset.*\n",
        "\n",
        "*We dropped \"Name\" column from new dataset, as \"Restaurant\" column has name of restaurant.*\n",
        "\n",
        "*We tried to find number of reviews for each restaurant.*\n",
        "* Each restaurant has total 100 reviews.\n",
        "\n",
        "*We tried to find out top 5 couisines in the dataset, which are most avialable:*\n",
        "* North Indian:  6000\n",
        "* Chinese:        4100\n",
        "* Continental:     2085\n",
        "* Biryani:       1500\n",
        "* Asian:      1400\n",
        "\n",
        "\n",
        "*We tried to find out top 5 reviewer in the dataset:*\n",
        "* Ankita\n",
        "* Parijat Ray\n",
        "* Kiran\n",
        "* Jay Mehta\n",
        "* Vedant Killa\n",
        "\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a new dataframe for visualization:\n",
        "df_rating = merged_df.groupby('Restaurant').agg({'Cost':'mean', 'Rating':'mean'}).sort_values( 'Cost', ascending = False).reset_index()\n",
        "df1 = df_rating.head(10)\n"
      ],
      "metadata": {
        "id": "bY15VHgcE1dY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# Visualizing top10 costliest restaurant:\n",
        "\n",
        "plt.figure(figsize=(20,6))\n",
        "sns.barplot(data = df1, x = 'Restaurant', y = 'Cost', hue = 'Rating')\n",
        "plt.title('Top 10 Costly Restaurant.', fontsize = 14)\n",
        "plt.xlabel('Restaurant Name', fontsize = 12)\n",
        "plt.ylabel(\"Estimated Dinning Cost Per Person\", fontsize = 12)\n",
        "plt.xticks(rotation = 90, fontsize = 8)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here.\n",
        "*Bar Charts are useful for comparing categorical variables.They allow us to clearly visualize differences between restaurant prices. It is useful to visualize top10 costly restaurants.*"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here. We found top10 costliest restaurants:\n",
        "1. Collage-Hyatt\n",
        "2. Feast - Sheraton\n",
        "3. 10 Downing Street\n",
        "4. Jonathan's Kitchen-Holiday Inn Express & Suites\n",
        "5. Cascade - Radisson\n",
        "6. Zega - Sheraton\n",
        "7. Mazzo - Marriott Executive Apartments\n",
        "8. B-Dubs\n",
        "9. Arena Eleven\n",
        "10. Barbeque Nation"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "\n",
        "*We found that these top restaurants can generate good revenue for Zomato.*\n",
        "\n",
        "*I haven't found any negative insights, but I would recommend that restaurants offer discounts to their regular customers. It could help them increase their sales.*"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a dataframe with last 10 datas:\n",
        "df2 = df_rating.tail(10)"
      ],
      "metadata": {
        "id": "xAu7QBqcVPJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Visualizing top10 affordable restaurants:\n",
        "\n",
        "plt.figure(figsize=(20,6))\n",
        "sns.barplot(data = df2, x = 'Restaurant', y = 'Cost', hue = 'Rating')\n",
        "plt.title('Top10 Affordable Restaurants.', fontsize = 14)\n",
        "plt.xlabel('Restaurant Name', fontsize = 12)\n",
        "plt.ylabel('Estimate Dinning Cost Per Person')\n",
        "plt.xticks(rotation = 90, fontsize = 8)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Answer Here:\n",
        "\n",
        "*Bar plots are useful in comparing categorical variables. They are useful in visualizing top10 affordable restaurants.*"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Answer Here:\n",
        "\n",
        "*These are top 10 most affordable restaurants:*\n",
        "\n",
        "1. Cream Store\n",
        "2. Tempteys\n",
        "3. The Old Madras Baking Company\n",
        "4. Shah Ghouse Spi Shawarma\n",
        "5. KS Bakers\n",
        "6. Asian Meal Box\n",
        "7. Hunger Maggi Point\n",
        "8. Momos Delight\n",
        "9. Amul\n",
        "10. Mohammedia Shawarma"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Answer Here*\n",
        "\n",
        "*The insights gained will definitely help in creating a new strategy for the company. It will assist the company in promoting these affordable restaurants to customers who seek affordable or group meals. This will undoubtedly help the company reach its target customers with an affordable menu.*\n",
        "\n",
        "*I haven't figured out any negative growth as such, but the company should assist these restaurants in reaching maximum customers, as these restaurants are affordable for the majority of customers in India. They can create a huge customer base for the company.*"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Observation:\n",
        "* The majority of the Top 10 costly restaurants, characterized by their higher prices, exhibit ratings exceeding 4. This suggests that patrons are willing to pay a premium for dining experiences associated with higher-rated establishments, indicating a positive correlation between cost and perceived quality.\n",
        "\n",
        "* Conversely, among the Top 10 affordable restaurants, which offer more budget-friendly options, ratings predominantly fall below 4. Notably, none of these establishments achieve a rating of 4 or higher. This disparity in ratings may reflect varying customer expectations and standards associated with more economical dining choices. It could also indicate that lower-priced restaurants face challenges in delivering experiences that consistently meet or exceed higher rating thresholds.\n",
        "\n",
        "* Additionally, it may be beneficial to explore potential factors contributing to the observed ratings disparity. This could include analyzing aspects such as cuisine type, service quality, ambiance, or location, which may influence customer perceptions and ratings across different restaurant categories"
      ],
      "metadata": {
        "id": "aoI9Q4jCFVXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making dataframe for cuisine visualization:\n",
        "df_cuisine = merged_df.groupby(['Restaurant', 'Cuisines']).agg({'Cost':'mean'}).sort_values('Cost', ascending = False).reset_index()\n",
        "df3 = df_cuisine.head(10)\n",
        "df3"
      ],
      "metadata": {
        "id": "Z3UlpGV1exPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting cuisines:\n",
        "cuisines_provided = df3['Cuisines'].str.split(', ', expand=True).stack()"
      ],
      "metadata": {
        "id": "kh1rWKzQqkGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing Cuisines provided in Top10 coslty restaurant and number of restaurant in which it is available:\n",
        "plt.figure(figsize=(20,6))\n",
        "sns.countplot(x = cuisines_provided, hue = cuisines_provided)\n",
        "plt.title('Cuisines Provided In top10 Costly Restaurants', fontsize = 14)\n",
        "plt.xlabel('Cuisines Name', fontsize = 12)\n",
        "plt.ylabel('Number Of  Restaurants Cuisines Available', fontsize = 12)\n",
        "plt.xticks(rotation = 45, fontsize = 10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4M6loVEPrb6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "*Bar plots are useful in comparing categorical variables. They are useful in visualizing cuisines available in top10 costly restaurants.*\n",
        "\n"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "\n",
        "*These are the cuisines provided in top10 costly restaurants:*\n",
        "1. North Indian - In 6 Restaurants\n",
        "2. Continental - In 5 Restaurants\n",
        "3. Italian - In 5 Restaurants\n",
        "4. Asian - In 5 Restaurants\n",
        "5. Chinese - In 2 Restaurants\n",
        "6. Shushi - In 2 Restuarants\n",
        "7. Modern Indian, Japanese, Salad, South Indian, American, Mediterranean, Kebab, BBQ - In 1 Restaurants"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "*Gained insights would help the company recommend suitable restaurants based on their cuisine choices.*\n",
        "\n",
        "*I don't think there are any insights that lead to negative growth. These cuisines are very famous and are provided by the restaurants.*"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making Dataframe for top10 affordable restaurant visualization:\n",
        "df4 = df_cuisine.tail(10)"
      ],
      "metadata": {
        "id": "BSSZx8Ob0OGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting cuisines:\n",
        "cuisines_provided2 = df4['Cuisines'].str.split(', ', expand=True).stack()"
      ],
      "metadata": {
        "id": "w7BB5mp_0d_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "#Visualizing Cuisines provided in Top10 affordable restaurant and number of restaurant in which it is available:\n",
        "plt.figure(figsize=(20,6))\n",
        "sns.countplot(x = cuisines_provided2, hue = cuisines_provided2)\n",
        "plt.title('Cuisines Provided In top10 Affordable Restaurants', fontsize = 14)\n",
        "plt.xlabel('Cuisines Name', fontsize = 12)\n",
        "plt.ylabel('Number Of  Restaurants Cuisines Available', fontsize = 12)\n",
        "plt.xticks(rotation = 45, fontsize = 10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here.\n",
        "Bar plots are useful in comparing categorical variables. They are useful in visualizing cuisines available in top10 affordable restaurants."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "*These are cuisines available in top10 most affordable restaurants:*\n",
        "1. Desserts - In 4 Restaurants\n",
        "2. Ice cream - In 3 Restaurants\n",
        "3. Bakery - In 3 Restaurants\n",
        "4. Fast Food - In 3 Restaurants\n",
        "5. Beverages, Lebanese, Asian, Momos, Street Food, Arabian - In 1 Restaurant"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "*Gained insights would help the company recommend suitable restaurants based on their cuisine choices.*\n",
        "\n",
        "*I don't think there are any insights that lead to negative growth. These cuisines are very famous and are provided by the restaurants.*\n"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Making dataframe for cuisine counts:\n",
        "famous_cuisine = merged_df['Cuisines'].str.split(', ', expand=True).stack()\n",
        "famous_cuisine"
      ],
      "metadata": {
        "id": "CvZ8FK2X4szM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "# Finding Famous cuisines based on availability:\n",
        "plt.figure(figsize=(20,6))\n",
        "sns.countplot(x = famous_cuisine, hue = famous_cuisine)\n",
        "plt.title('Famous Cuisines Based On Availability', fontsize = 14)\n",
        "plt.xlabel('Cuisines Name', fontsize = 12)\n",
        "plt.ylabel('Number Of Restaurants With Cuisines Available', fontsize = 12)\n",
        "plt.xticks(rotation = 90, fontsize = 10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "Bar plots are useful in comparing categorical variables. They are useful in visualizing differences between restaurant prices."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "These are some most famous cuisines based on availability:\n",
        "1. North Indian - Available in 6000 restaurants.\n",
        "2. Chinese - Available in 4000 restaurants.\n",
        "3. Biryani, Italian - Available in around 1500 restaurants.\n",
        "4. Asian, Fast Food - Available in around 1400 restaurants."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* These insights would help the company make better recommendations for their customers.\n",
        "\n",
        "* I haven't found any insights that indicate negative growth."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing dataframe before making visualization:\n",
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "KnW_-5JCCNwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a groupby dataframe of restaurant and rating for futher visualization process:\n",
        "restaurant_rating = merged_df.groupby('Restaurant').agg({'Rating':'mean', 'Cost': 'mean'}).sort_values('Rating', ascending = False).reset_index()\n",
        "df6 = restaurant_rating.head(10)\n",
        "df6"
      ],
      "metadata": {
        "id": "Ev4twDiEDAfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# Finding and visualizing restaurants with the highest ratings with a hue on cost.\n",
        "plt.figure(figsize=(20, 6))\n",
        "sns.barplot(data = df6, x = 'Restaurant', y = 'Rating', hue = 'Cost')\n",
        "plt.title('Restaurant With Highest Rating', fontsize = 14)\n",
        "plt.xlabel('Restaurants Name', fontsize = 12)\n",
        "plt.ylabel('Average Rating Given By Reviewer To Restaurant', fontsize = 12)\n",
        "plt.xticks(rotation = 90, fontsize = 10)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here.\n",
        "Bar plots are useful in comparing categorical variables. They are useful in visualizing differences between restaurant rating, hued on cost."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "These are top 10 restaurants with highest rating:\n",
        "\n",
        "1. AB's Absolute Barbeque       - 4.88\n",
        "2. B-Dubs                       - 4.81\n",
        "3. 3B's-Buddies, Bar & Barbecue - 4.76\n",
        "4. Paradise - 4.70\n",
        "5. Flechazo - 4.66\n",
        "6. The Indi Grill - 4.60\n",
        "7. Zega-Sheraton - 4.45\n",
        "8. Over The Moon Brew Company - 4.38\n",
        "9. Beyond Flavours - 4.28\n",
        "10. Cascada-Paradise - 4.26"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* Gained insights would help the company recommend restaurants to customers based on the highest ratings.\n",
        "\n",
        "* Customers can find the best restaurants for them based on ratings.\n",
        "\n",
        "* High ratings are a positive indicator, while low ratings are a negative indicator."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making dataframe for lowest rating restaurant visualization:\n",
        "df7 = restaurant_rating.tail(10)\n",
        "df7"
      ],
      "metadata": {
        "id": "12fq_3dkMdnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Finding top 10 restaurants with lowest ratings with a hue on Cost:\n",
        "plt.figure(figsize=(20, 6))\n",
        "sns.barplot(data = df7, x = 'Restaurant', y = 'Rating', hue = 'Cost')\n",
        "plt.title('Restaurant With Lowest Ratings', fontsize = 14)\n",
        "plt.xlabel('Restaurant Names', fontsize = 12)\n",
        "plt.ylabel('Average Rating Given By Reviewer To Restaurants', fontsize = 12)\n",
        "plt.xticks(rotation = 90, fontsize = 10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "Bar plots are useful in comparing categorical variables. They are useful in visualizing differences between restaurant prices."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "*These top10 restaurants with least rating.*\n",
        "1. Desi Bytes - 2.9\n",
        "2. Club Rogue - 2.88\n",
        "3. KFC - 2.85\n",
        "4. The Chocolate Room - 2.83\n",
        "5. Shree Santosh Dhaba Family Restaurant - 2.83\n",
        "6. Behrouz Biryani - 2.82\n",
        "7. Mathura Vilas - 2.82\n",
        "8. Pakwaan Grand - 2.71\n",
        "9. Asian Meal Box - 2.58\n",
        "10. Hotel Zara Hi-Fi - 2.4"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* Gained insights would help the company recommend restaurants to customers based on the highest ratings.\n",
        "\n",
        "* Customers can find the best restaurants for them based on ratings.\n",
        "\n",
        "* High ratings are a positive indicator, while low ratings are a negative indicator."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Observation of Rating to Cost Comparitive Visualization:\n",
        "* Restaurants rated above 4.25 consistently achieve high customer satisfaction. Among these top-rated establishments, dining costs range from 800 to 1800 per person, showcasing a diverse yet elevated pricing range that caters to discerning patrons seeking exceptional dining experiences.\n",
        "* Conversely, restaurants garnering ratings below 3 occupy the lower end of the satisfaction spectrum. Despite this, the dining costs vary noticeably, with the most expensive restaurant charging 900 per person and the most affordable option priced at a modest 200 per person. This disparity underscores the complex interplay between perceived value, service quality, and customer expectations within the lower-rated segment of the dining landscape."
      ],
      "metadata": {
        "id": "-xA-ztjPHz69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5AKGU5KnHzs1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing dataframe:\n",
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "eVQt7jMwJotr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling missing values with an empty string to avoid split errors\n",
        "merged_df['Metadata'] = merged_df['Metadata'].fillna('')\n",
        "\n",
        "\n",
        "# Split the 'Metadata' column into two columns named 'Review' and 'Followers'\n",
        "merged_df[['Review_count', 'Followers']] = merged_df['Metadata'].str.split(', ', expand=True)\n"
      ],
      "metadata": {
        "id": "tcTMjaEMTbm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing dataframe after spliting metadata column:\n",
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "HJQ2bnrIToIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#counting missing value:\n",
        "merged_df.isna().sum()"
      ],
      "metadata": {
        "id": "58kxmMU6VHrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# handling null value in followers column:\n",
        "merged_df['Followers'] = merged_df['Followers'].fillna(0)"
      ],
      "metadata": {
        "id": "k82YFAIXV5Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding non-null value after handling missing value:\n",
        "merged_df.info()"
      ],
      "metadata": {
        "id": "3IqN_zB0UTZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Reviews columns with integer value only:\n",
        "merged_df['Reviews'] = merged_df['Review_count'].str.extract(r'(\\d+)')\n",
        "merged_df['Text'] = merged_df['Review_count'].str.replace(r'\\d+', '', regex=True)\n"
      ],
      "metadata": {
        "id": "upPFlZxiXibT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Follower columns with interger value only:\n",
        "merged_df['Follower'] = merged_df['Followers'].str.extract(r'(\\d+)')\n",
        "merged_df['Texts'] = merged_df['Followers'].str.replace(r'\\d+', '', regex=True)"
      ],
      "metadata": {
        "id": "vPqFQLD3YTKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "E2sThEPcYMs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping all not necessary columns:\n",
        "merged_df.drop(['Review_count', 'Followers','Text', 'Texts'], axis=1, inplace = True)\n",
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "JRDnIlqwYoq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Columns in dataframe:\n",
        "merged_df.columns"
      ],
      "metadata": {
        "id": "lvCqjhdYbtOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count of reveviwer's visit in restaurant using Zomato:\n",
        "merged_df['Reviewer'].value_counts()"
      ],
      "metadata": {
        "id": "z5GcP3GMc36t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "Am0MZqOM_RNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping unknown rows as its number may impact the analyis:\n",
        "merged_df.drop(merged_df[merged_df['Reviewer'] == 'unknown'].index, inplace=True)\n"
      ],
      "metadata": {
        "id": "2ibRWPeufPPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Visualizing Top10 Reviewer with most Restaurant reviewed:\n",
        "plt.figure(figsize=(20, 6))\n",
        "sns.countplot(data = merged_df, x = 'Reviewer', order = merged_df['Reviewer'].value_counts().iloc[:10].index, hue = 'Cost')\n",
        "plt.title('Top Reviewers', fontsize = 14)\n",
        "plt.xlabel('Reviewer Name', fontsize = 12)\n",
        "plt.ylabel('Number Of Restaurant Reviewed', fontsize = 12)\n",
        "plt.xticks(rotation = 90, fontsize = 10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "Bar plots are useful in comparing categorical variables. They are useful in visualizing differences between restaurant prices."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "These are top10 reviewer with most restaurant reviewed:\n",
        "1. Parijat Ray - 13 Restaurant\n",
        "2. Ankita - 13 Restaurant\n",
        "3. Kiran - 12 Restaurant\n",
        "4. Vedant Killa, Jay Mehta = 11 Restaurant\n",
        "5. Manojkumar, Priyanka, Suraj Karambe, Sravani, Shiva Kumar = 10 Restaurant\n"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* Reviewers are the customers who visit restaurants and give reviews based on their experiences. Having a good understanding of these customers and the types of restaurants they visit would definitely benefit the business.\n",
        "* I don't find any insights that lead to negative growth."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Observation:\n",
        "* Majority of the top reviewers are prefering affordable restaurants rather than costly restaurants.\n",
        "* They visited more than once in many restaurants."
      ],
      "metadata": {
        "id": "b2vXoq2hgleH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking non-null counts:\n",
        "merged_df.info()"
      ],
      "metadata": {
        "id": "BV5zWwKHsd5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting null to 0 on Follower column:\n",
        "merged_df['Follower'] = merged_df['Follower'].fillna(0)"
      ],
      "metadata": {
        "id": "pFeNRvLvtit-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting datatype of Reviews and Follower:\n",
        "merged_df['Reviews'] = merged_df['Reviews'].astype(int)\n",
        "merged_df['Follower'] = merged_df['Follower'].astype(int)"
      ],
      "metadata": {
        "id": "S4yAQ7u_smec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a grouped dataframe of Reviewer and sum of their reviews:\n",
        "df_reviews = merged_df.groupby('Reviewer').agg({'Reviews': 'sum'}).sort_values('Reviews', ascending = False)\n",
        "df9 = df_reviews.head(10)\n",
        "df9"
      ],
      "metadata": {
        "id": "GVJNFDGJmwD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# Visualizing Top 10 Reviewer with highest reviews:\n",
        "plt.figure(figsize = (20, 6))\n",
        "sns.barplot(data = df9, x = 'Reviewer', y = 'Reviews', hue = 'Reviews')\n",
        "plt.title('Top10 Reviewer With Highest Reviews', fontsize = 14)\n",
        "plt.xlabel('Reviewer Name', fontsize = 12)\n",
        "plt.ylabel('Total Reveiws Of The Reviewer', fontsize = 12)\n",
        "plt.xticks(rotation = 90, fontsize = 10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "Bar plots are useful in comparing categorical variables. They are useful in visualizing differences between restaurant prices."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df9.head(10)"
      ],
      "metadata": {
        "id": "MlVJNbowvmgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "These are the top10 Reviewer with highest reviews:\n",
        "1. Anvesh Chowdary : 3093 Reviews\n",
        "2. Raghu : 2658 Reveiws\n",
        "3. Parijat Ray : 1898 Reviews\n",
        "4. Sambhangi Sandeep : 1638 Reviews\n",
        "5. Gourmet Hunter : 1617 Reviews\n",
        "6. Avin Seth : 1578 Reviews\n",
        "7. Shravya Gunipudi : Reviews\n",
        "8. Priyambada Choudhary : 1376 Reviews\n",
        "9. Shreshth malhotra : 1375 Reviews\n",
        "10. Epicurean Tales : 1356 Reviews"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* Yes, I think gained insights would help create a positive business impact. If a company knows their target customers, it would definitely help the business.\n",
        "* I haven't found any negative insights that lead to negative growth."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a group of Restaurant with Total Reviews give by Reviwer.\n",
        "df_reviews = merged_df.groupby('Restaurant').agg({'Reviews': 'sum', 'Rating':'mean'}).sort_values('Reviews', ascending = False)\n",
        "df10 = df_reviews.head(10)\n",
        "df10"
      ],
      "metadata": {
        "id": "8J-sH99jxhhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code:\n",
        "# Visualizing Top10 Restaurants with the highest review counts by the reviewers:\n",
        "plt.figure(figsize = (20, 6))\n",
        "sns.barplot(data = df10, x = 'Restaurant', y = 'Reviews', hue = 'Rating')\n",
        "plt.title('Top10 Restaurants With Highest Number Reviews By Reviewers', fontsize = 14)\n",
        "plt.xlabel('Restaurants Name', fontsize = 12)\n",
        "plt.ylabel('Total Reviews By The Reviewers', fontsize = 12)\n",
        "plt.xticks(rotation = 90, fontsize = 10)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "Bar plots are useful for comparing categorical variables and visualizing differences between restaurants with the highest reviews. They can be especially effective when coloring bars based on ratings."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df10"
      ],
      "metadata": {
        "id": "iR6wZMGR_hv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "Some important Insights:\n",
        "* Labonel has 6628 reviews but rating is 3.915.\n",
        "* Cascade - Radison has 4444 reviews but rating is 4.260."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* I am confident enough that gained insights would help the company to improve its business model.\n",
        "* I haven't found any insights that lead to negative growth. We have to look for the reason why restaurants with the highest reviews count do not have the best ratings.\n"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing dataframe before making visualization:\n",
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "xj4rd0LK4FLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making a group of Restaurant with Reviews count and Avg rating and taking top 10 restaurant:\n",
        "df_reviews = merged_df.groupby('Restaurant').agg({'Reviews': 'sum', 'Rating':'mean'}).sort_values('Reviews', ascending = False)\n",
        "df11_rating = df_reviews.head(10)\n",
        "\n",
        "#Making a group of Restaurant with Reviews count and Avg cost and taking top 10 restaurant:\n",
        "df_cost = merged_df.groupby('Restaurant').agg({'Reviews': 'sum', 'Cost':'mean'}).sort_values('Reviews', ascending = False)\n",
        "df11_cost = df_cost.head(10)"
      ],
      "metadata": {
        "id": "e4KuRr4L4KgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "plt.figure(figsize = (20, 6))\n",
        "sns.barplot(data = df11_rating, x = 'Restaurant', y = 'Reviews', hue = 'Rating')\n",
        "sns.lineplot(data = df11_cost, x = 'Restaurant', y = 'Cost', color = 'red', marker = 'o')\n",
        "plt.title('Top10 Restaurant With Highest Reviews And Relation Between Rating And Cost', fontsize = 14)\n",
        "plt.xlabel('Restaurant Name', fontsize = 12)\n",
        "plt.ylabel('Total Reviews', fontsize = 12)\n",
        "plt.xticks(rotation = 90, fontsize = 10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "Bar plots with line plots are useful to visualize relationships between many categories and numerical variables. It helped to visualize the relationship between Costs and Ratings for the highest reviewed restaurants."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* We were trying to find relationship between Cost and Rating, for the restauratns with highest reviews.\n",
        "* We haven't found any clear relationship between Cost and Rating."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* Gained insights give us a good understanding of customer behavior towards costs and ratings.\n",
        "* They did not rate any restaurant based solely on cost; there could be many other reasons as well.\n",
        "* These insights would help the company improve their service and food quality, as customers don't mind costs much when giving ratings"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking non-null value:\n",
        "merged_df.info()"
      ],
      "metadata": {
        "id": "_e8Af13qGVoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing dataframe before making visualization:\n",
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "xlwBSFvGDiNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a dataframe for a group of Reviewer, Pictures and Follower:\n",
        "df_follower_picture = merged_df.groupby('Reviewer').agg({ 'Follower':'sum', 'Rating':'mean'}).sort_values('Follower', ascending = False)\n",
        "df12 = df_follower_picture.head(10)"
      ],
      "metadata": {
        "id": "9oF9NwmYD4sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code:\n",
        "# Visualizing top10 Reviewer with highest followers and average Rating given to the Restaurants:\n",
        "plt.figure(figsize = (20, 6))\n",
        "sns.barplot(data = df12, x = 'Reviewer', y = 'Follower', hue = 'Rating')\n",
        "plt.title('Top 10 Reviewers by Follower Count', fontsize = 14)\n",
        "plt.xlabel('Reviewer Name', fontsize = 12)\n",
        "plt.ylabel('Follower Count', fontsize = 12)\n",
        "plt.xticks(rotation = 90, fontsize = 10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "Bar plots are useful for visualizing the difference between two variables. It is useful to see the top Reviewers with the highest followers."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df12.head(10)"
      ],
      "metadata": {
        "id": "OBuzoyThvy4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "These are top10 Reviewer with highest follower:\n",
        "1. Satwinder Singh : 40230\n",
        "2. Foodies Hyderabad : 37976\n",
        "3. Srinivas : 30514\n",
        "4. Samar Nawabs : 22658\n",
        "5. Food Nawabs : 22129\n",
        "6. ASH&B2 : 20793\n",
        "7. Rohit Reddy : 14860\n",
        "8. Nishtha Chandarana : 14812\n",
        "9. Varun Reddy : 13959\n",
        "10. Eat_vth_me : 13320\n",
        "\n",
        "*These reviewers seem more like bloggers or YouTubers, as their names resemble blog or channel names. With a substantial following, their reviews carry significant weight for Zomato and especially for the restaurants.*\n",
        "\n",
        "* Foodies Hyderabad has given an average 4.4 rating to the restaurants and it has a very good following of 37976.\n",
        "* Eat_vth_me has given an average 4.8 rating to the restaurants and it has a following of 13320.\n",
        "* Rest of the customers have given less than 4.4 rating to the restaurants and that is a matter of concern.\n",
        "* Varun Reddy has given an average rating of less than 3 to the restaurants. He has a good following of 13959. Zomato should try to find out the reason for such a low rating."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "I am confident that gained insights will help create a positive business impact. Zomato should pay attention to the reviews of these customers, as they will be followed by their large follower base. While I haven't identified any negative insights, it's worth noting that some customers have given very low ratings to restaurants, which could potentially harm business. The company should investigate the reasons behind these low ratings. Leveraging the substantial follower base of these customers, positive reviews and ratings could greatly benefit the business."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing dataframe before making visualization:\n",
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "nDQTl-gB8hIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Before coverting datatype of date column:\n",
        "merged_df.info()"
      ],
      "metadata": {
        "id": "shPrqCGGAqjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting Time column to datetime type:\n",
        "merged_df['Time'] = pd.to_datetime(merged_df['Time'])\n"
      ],
      "metadata": {
        "id": "KmSOLGjqBjTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#After converting datatype of date column:\n",
        "merged_df.info()"
      ],
      "metadata": {
        "id": "x8_PcrVpCjvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making a column of Year form Time column\n",
        "merged_df['Year'] = merged_df['Time'].dt.year"
      ],
      "metadata": {
        "id": "C_0Vr9SLCU_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Verifying the extraction of Year from time column and making of new Year column:\n",
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "k_hfiK8wCojN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unique Years:\n",
        "merged_df['Year'].unique()"
      ],
      "metadata": {
        "id": "8yXxo0j3DUzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing restaurant count dataframe:\n",
        "df_restaurant_count = merged_df.groupby(['Year']).agg({'Restaurant':'count', 'Cost':'sum'}).reset_index()\n",
        "df_restaurant_count"
      ],
      "metadata": {
        "id": "Qgm8RsVDJksQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing Estimated Revenue For Number Of Restaurant:\n",
        "from matplotlib.ticker import ScalarFormatter\n",
        "plt.figure(figsize = (15, 8))\n",
        "sns.barplot(data = df_restaurant_count, x = 'Year', y = 'Cost' , hue = 'Restaurant' )\n",
        "plt.title('Estimated Total Revenue Each Year', fontsize = 14)\n",
        "plt.xlabel('Years', fontsize = 12)\n",
        "plt.ylabel('Estimated Total Revenue', fontsize = 12)\n",
        "plt.gca().yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
        "plt.ticklabel_format(style='plain', axis='y')\n",
        "plt.yticks(rotation = 90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CjIcFk-vJ7P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "Bar charts provide a clear visual representation of data, allowing us to easily compare the estimated total revenue and the number of restaurants for each year. With bar charts, we can quickly visualize differences between the revenue and restaurant counts across different years."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* We can clearly observe significant improvements in the estimated total revenue and the number of restaurants each year.\n",
        "* Additionally, it is evident that there was just a slight increase in restaurant counts in 2019 compared to 2018, while the estimated total revenue continued to show grow very good."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* The gained insights would help the company encourage investors to invest in the company. The company has shown significant growth in 2018 and 2019. It will be beneficial for the company to gain shareholders' and other stakeholders' confidence.\n",
        "* There is some slow growth observed between 2018 and 2019. However, the company must ensure consistency in its growth trajectory.\n"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization:\n",
        "\n",
        "# Computing the correlation matrix:\n",
        "correlation_matrix = merged_df.corr(numeric_only=True)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
        "plt.title('Correlation Map of merged_df')\n",
        "\n",
        "# Show the plot:\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* Correlation maps are useful for visualizing relationships between different variables, providing a clear understanding of their interrelationships."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* We identified a strong relationship between the 'Follower' and 'Reviews' columns. Additionally, there were observed relationships between 'Year' and 'Cost', 'Follower' and 'Pictures', and 'Reviews' and 'Pictures'"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization:\n",
        "plt.figure(figsize = (20, 20))\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.pairplot(data = merged_df)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "Pair Plot is useful for identifying overall patterns and trends in the dataframe. It is also helpful in detecting outliers and understanding the overall relationships between variables."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "*We can observe a positive trend in the dataset, indicating that the company is experiencing consistent growth each year. Specifically:*\n",
        "\n",
        "* The number of company's customers is increasing annually.\n",
        "* The count of company's restaurant partners is also growing year by year.\n",
        "* Company's revenue shows a steady increase over time.\n",
        "\n",
        "*This pair plot provides a comprehensive overview of the company's performance in a single graph, allowing us to easily grasp the positive trends in its growth.*"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "Three Hypothetical Statements:\n",
        "1. Revenue is increasing year by year.\n",
        "2. There is a relation between followers and reviews.\n",
        "3. Costly restaurants have good ratings."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* Null Hypothesis: Revenue is not increasing every year, it is same for every year.\n",
        "* Alternate Hypothesis: Revenue is increasing every year."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating years and costs variable:\n",
        "years = merged_df['Year']\n",
        "costs = merged_df['Cost']\n",
        "\n",
        "# Adding intercept term for the regression model:\n",
        "years_with_intercept = sm.add_constant(years)\n",
        "\n",
        "# Fiting linear regression model:\n",
        "model = sm.OLS(costs, years_with_intercept).fit()\n",
        "\n",
        "# finding p_value:\n",
        "p_value = model.pvalues[1]\n",
        "\n",
        "# Print the p-value\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Check if the p-value is less than the significance level of 0.5 to determine whether to reject the null hypothesis or to fail to reject the null hypothesis:\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis. There is evidence to suggest that costs are increasing every year.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant evidence to suggest that costs are increasing every year.\")\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "I used a linear regression model to obtain the p-value, which helps determine the statistical significance of the relationship between the independent and dependent variables. To accomplish this, I imported statsmodels.api as sm. Then, I fitted the model using ordinary least squares (OLS) regression. By examining the p-value associated with the coefficient of the independent variable in the regression output, I assessed whether there was a significant relationship between the variables. A low p-value (< 0.05) suggests that the relationship is statistically significant, providing evidence for the trend observed in the data."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* Linear regression is useful for testing trends over time or across different conditions, making it a valuable tool for assessing relationships between variables.\n",
        "\n",
        "* The straightforward interpretation of the p-value in linear regression enables easy assessment of the statistical significance of the observed relationships.\n",
        "* Additionally, linear regression allows for the inclusion of other relevant factors in the analysis, making it possible to control for potential confounding variables and verify the accuracy of the results.\""
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* Null Hypothesis: There is no relation between Follower and Reviews.\n",
        "* Alternate Hypothesis: There is relation between Follower and Reviews."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extacting data from both column:\n",
        "followers = merged_df['Follower']\n",
        "reviews = merged_df['Reviews']\n",
        "\n",
        "# Calculating Pearson correlation coefficient and p-value:\n",
        "correlation_coefficient, p_value = stats.pearsonr(followers, reviews)\n",
        "\n",
        "# Printing results:\n",
        "print(\"Pearson correlation coefficient:\", correlation_coefficient)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Determining significance:\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant relationship between 'Follower' and 'Reviews' columns.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant relationship between 'Follower' and 'Reviews' columns.\")\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* I used the Pearson correlation coefficient test to obtain the p-value.\n",
        "* The Pearson correlation coefficient measures the strength and direction of the linear relationship between two continuous variables."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "The Pearson correlation coefficient measures the strength and direction of the linear relationship between two continuous variables. It is useful to find relation between 'Follower' and 'Reviews' columns."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* Null Hypothesis: There is no relationship between 'Cost' and 'Rating'.\n",
        "* Alternate Hypothesis: There is some relationship between 'Cost' and 'Rating'."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# Extracting 'Cost' and 'Rating' columns data:\n",
        "cost = merged_df['Cost']\n",
        "rating = merged_df['Rating']\n",
        "\n",
        "# Calculating Pearson correlation coefficient and p-value:\n",
        "correlation_coefficient, p_value = stats.pearsonr(cost, rating)\n",
        "\n",
        "# Printing results:\n",
        "print(\"Pearson correlation coefficient:\", correlation_coefficient)\n",
        "print(\"P-value:\", p_value)\n",
        "\n",
        "# Determining significance:\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant relationship between 'Cost' and 'Rating' columns.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant relationship between 'Cost' and 'Rating' columns.\")\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "I used the Pearson correlation coefficient test to obtain the p-value."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* The Pearson correlation coefficient measures the strength and direction of the linear relationship between two continuous variables. It is useful to find relation between 'Cost' and 'Rating' columns."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation:\n",
        "merged_df.isna().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* There is no missing value in the dataset so, no imputation required."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing dataframe before finding and handling outliers:\n",
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "VaxstEpHLRkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Describing numerical variables:\n",
        "merged_df.describe()"
      ],
      "metadata": {
        "id": "LxWpQFqdVTQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding outliers in Rating column:\n",
        "sns.boxplot(merged_df['Rating'])\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*We can observe there is no outlier in Rating column.*"
      ],
      "metadata": {
        "id": "RT7MerPiUgkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding outliers in Pictures column:\n",
        "sns.boxplot(merged_df['Pictures'])"
      ],
      "metadata": {
        "id": "DvFu9CbjUpVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling outliers:\n",
        "iqr_picture = 0 - 0\n",
        "merged_df.loc[merged_df['Pictures'] > (1.5 * iqr_picture) + 0 , 'Pictures'] = merged_df['Pictures'].median()"
      ],
      "metadata": {
        "id": "XxSi-U2tVFui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot after handling outliers:\n",
        "sns.boxplot(merged_df['Pictures'])"
      ],
      "metadata": {
        "id": "eUumsBGXjUWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding outliers in Cost:\n",
        "sns.boxplot(merged_df['Cost'])"
      ],
      "metadata": {
        "id": "Kcgo7SjTj3lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe two outliers, we will handle it with median imputation."
      ],
      "metadata": {
        "id": "yXnRhCiWkCHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling outliers:\n",
        "iqr_cost = 1200 - 500\n",
        "merged_df.loc[merged_df['Cost'] > (1.5 * iqr_cost) + 1200 , 'Cost'] = merged_df['Cost'].median()"
      ],
      "metadata": {
        "id": "6Rsbrtb9kJbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot after handling outliers:\n",
        "sns.boxplot(merged_df['Cost'])"
      ],
      "metadata": {
        "id": "lyuil83skgcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding outliers in Reviews:\n",
        "sns.boxplot(merged_df['Reviews'])"
      ],
      "metadata": {
        "id": "l6PXZBNgmCHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe few outliers lets handle it with median imputation."
      ],
      "metadata": {
        "id": "MOqYAzhunY0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling outliers:\n",
        "iqr_reviews = 22 - 1\n",
        "merged_df.loc[merged_df['Reviews'] > (1.5 * iqr_reviews) + 22 , 'Reviews'] = merged_df['Reviews'].median()"
      ],
      "metadata": {
        "id": "tQ86XJ6cmZV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Boxplot after handling outliers:\n",
        "sns.boxplot(merged_df['Reviews'])"
      ],
      "metadata": {
        "id": "ip5GmwaLmt7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding outliers in Follower:\n",
        "sns.boxplot(merged_df['Follower'])"
      ],
      "metadata": {
        "id": "c9xxlfJQnXAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling outliers in Follower:\n",
        "iqr_follower = 63 - 1\n",
        "merged_df.loc[merged_df['Follower'] > (1.5 * iqr_reviews) + 63 , 'Follower'] = merged_df['Follower'].median()"
      ],
      "metadata": {
        "id": "PmwIxtCZn66p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Boxplot after handling outliers:\n",
        "sns.boxplot(merged_df['Follower'])"
      ],
      "metadata": {
        "id": "aHJ_d0zNoTHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        " Median imputation is a useful technique for handling missing or outlier data, particularly in situations where the mean may be influenced by extreme values or when the underlying distribution of the data is skewed. It provides a simple and robust approach to imputing missing values and handling outliers while preserving the overall characteristics of the dataset."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "1xSWp6jwpcbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding unique Reviewer count:\n",
        "merged_df['Reviewer'].nunique()"
      ],
      "metadata": {
        "id": "wZG8pY5psYHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing using inbuilt lower():\n",
        "def lower_casing(text):\n",
        "  ''' function takes string and convert it to lower case '''\n",
        "  list_of_words = [letter.lower() for letter in text.split()]\n",
        "  return \" \".join(list_of_words)\n",
        "\n",
        "merged_df['Review'] = merged_df['Review'].apply(lower_casing)"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "WP-IR7jh26IM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required library for removing punctuations from a string:\n",
        "import string\n",
        "\n",
        "# Removing Punctuations:\n",
        "def remove_punctuation(text):\n",
        "    ''' function takes a string and remove punctuation from it '''\n",
        "    return ''.join([t for t in text if t not in string.punctuation])\n",
        "\n",
        "\n",
        "merged_df['Review'] = merged_df['Review'].apply(remove_punctuation)\n"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "hdjmFC5h5tGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing  digits:\n",
        "def remove_digits(text):\n",
        "  ''' function takes a string and remove any digits from it '''\n",
        "  num = '1,2,3,4,5,6,7,8,9,0'\n",
        "  return ''.join([s for s in text if s not in num])\n",
        "\n",
        "merged_df['Review'] = merged_df['Review'].apply(remove_digits)\n",
        "\n",
        "\n",
        "# Removing URLs:\n",
        "def remove_url(text):\n",
        "  ''' funtiong takes a string and remove any urls from it '''\n",
        "  return ''.join([s for s in text if s not in ['com', 'www', 'https//']])\n",
        "\n",
        "\n",
        "merged_df['Review'] = merged_df['Review'].apply(remove_url)\n"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "ro8k2fRQ8zN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary library:\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "-v5MnnEKGKKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing Stopwords:\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "  ''' funtion taking a string and removing stopwords '''\n",
        "\n",
        "  return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "\n",
        "merged_df['Review'] = merged_df['Review'].apply(remove_stopwords)\n"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "ppLi1mF4GeQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing White spaces:\n",
        "def remove_whitespace(text):\n",
        "  ''' function takes a string and remove white space from it '''\n",
        "  return ' '.join([word.strip() for word in text.split()])\n",
        "\n",
        "merged_df['Review'] = merged_df['Review'].apply(remove_whitespace)"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "lH86mzV1IMJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary library for tokenization:\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#Defining a word token function:\n",
        "def word_token(text, count_vectorizer):\n",
        "    ''' function takes a dataset and convert it to tokens '''\n",
        "    count_vectorizer.fit_transform(text)\n",
        "    return count_vectorizer.vocabulary_.items()\n",
        "\n",
        "# Initializing CountVectorizer outside the function:\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# Calling the function with the CountVectorizer object as a parameter:\n",
        "dictionary_cluster_col = word_token(merged_df['Review'], count_vectorizer)\n",
        "print(dictionary_cluster_col)\n",
        "\n"
      ],
      "metadata": {
        "id": "wMaGpiVpZAUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloding necessary library:\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "5U2R3_KEpQpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text normalization using lemmatization:\n",
        "def lemmatize_text(text):\n",
        "    ''' function takes a string and performs lemmatization '''\n",
        "    # Tokenizing text\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Initializing WordNet lemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # Lemmatizing tokens:\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Joining lemmatized tokens back into a string:\n",
        "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
        "\n",
        "    return lemmatized_text\n",
        "\n",
        "# Applying lemmatization to the 'Review' column:\n",
        "merged_df['Lemmatized_Review'] = merged_df['Review'].apply(lemmatize_text)\n",
        "\n",
        "\n",
        "merged_df.head(2)\n"
      ],
      "metadata": {
        "id": "zFu-Qhr2pBeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?\n",
        "* We are using lemmatization technique.\n",
        "* We are using WordNetLemmatizer() for text normalization.\n",
        "* Lemmatization technique helps to get original word of the text without changing its meaning.\n",
        "* It is easy to apply technique as well."
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Counting words in the Review column:\n",
        "word_counts = merged_df['Review'].str.split(expand=True).stack().value_counts()\n",
        "word_counts"
      ],
      "metadata": {
        "id": "O_1l8ldBOG82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "I have used the lemmatization technique for text normalization. Lemmatization is useful for reducing word variations and preserving their real meaning."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary library for text vectorization:\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def tfidf_vectorization(data_column, min_df_prop, max_df_prop):\n",
        "    # Initializing TF-IDF vectorizer:\n",
        "    tfidf_vectorizer = TfidfVectorizer(min_df=min_df_prop, max_df=max_df_prop)\n",
        "\n",
        "    # Fiting and transforming the data column:\n",
        "    features_array = tfidf_vectorizer.fit_transform(data_column).toarray()\n",
        "\n",
        "    # Extacting features name:\n",
        "    features_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "    return features_array, features_names\n",
        "\n",
        "# Example usage\n",
        "min_df_proportion = 1\n",
        "max_df_proportion = 90\n",
        "features_array, features_names = tfidf_vectorization(merged_df['Review'], min_df_proportion, max_df_proportion)\n",
        "print(\"TF-IDF Features Array Shape:\", features_array.shape)\n",
        "print(\"Number of Features:\", len(features_names))\n"
      ],
      "metadata": {
        "id": "QzMwQNin80Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "I have used TF-IDF vectorrization technique. TF-IDF is a widely used and effective text vectorization technique that captures both the local importance of terms within documents and their global importance across the corpus. It is particularly useful when the goal is to extract meaningful features from text data for tasks such as document classification, information retrieval, and text mining."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary library for sentiment analysis:\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Downloading the VADER(Valence Aware Dictionary and sEntiment Reasoner) lexicon:\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Initializing the VADER sentiment analyzer:\n",
        "sid = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "EeD1q1SpVwei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get sentiment score for each review\n",
        "def get_sentiment(review):\n",
        "    sentiment_score = sid.polarity_scores(review)\n",
        "    if sentiment_score['compound'] >= 0.05:\n",
        "        return 1  # Positive\n",
        "    elif sentiment_score['compound'] <= -0.05:\n",
        "        return -1  # Negative\n",
        "    else:\n",
        "        return 0  # Neutral\n",
        "\n",
        "# Apply sentiment analysis to the Review column\n",
        "merged_df['Sentiment'] = merged_df['Review'].apply(get_sentiment)"
      ],
      "metadata": {
        "id": "YwIfXCf2V93V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a new column satisfied based on rating and positive words in the review:\n",
        "merged_df['Satisfied'] =  (merged_df['Sentiment'] == 1).astype(int)\n"
      ],
      "metadata": {
        "id": "K7nOLRqlQHDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating new dataset:\n",
        "new_restaurant_df = merged_df[[ 'Rating', 'Cost', 'Satisfied', 'Reviews', 'Follower','Sentiment']]\n"
      ],
      "metadata": {
        "id": "h55FkJzFV6S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have already created necessary columns from Metadata and Time column."
      ],
      "metadata": {
        "id": "AYZXc6FTDqKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing the correlation matrix:\n",
        "correlation_matrix = new_restaurant_df.corr(numeric_only=True)\n",
        "\n",
        "# Creating a heatmap of the correlation matrix:\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Plot of Features')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "We are using the correlation matrix to determine whether a column is useful or not, by assessing its independence or dependence on other variables."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* We observe correlations between Rating, Cost, Reviews, Followers, Satisfied and Sentiment."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z-En5ktJH-ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on my understanding, data transformation is not necessary for the merged_df dataset."
      ],
      "metadata": {
        "id": "EH7YJiJ2HvCs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "I don't think that dimensionality reduction is required, we have all the sufficient vairables for futher analysis."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary liblrary data spliting:\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "X_train, X_test, y_train, y_test = train_test_split(new_restaurant_df.drop(\"Sentiment\",axis=1),new_restaurant_df[\"Sentiment\"], test_size = 0.3, random_state = 0)\n",
        "\n",
        "# describes info about train and test set\n",
        "print(\"X_train dataset: \", X_train.shape)\n",
        "print(\"y_train dataset: \", y_train.shape)\n",
        "print(\"X_test dataset: \", X_test.shape)\n",
        "print(\"y_test dataset: \", y_test.shape)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "* We have used a 70:30 ratio to split the dataset, with 70% for the training set and 30% for the testing set.\n",
        "\n",
        "* If we use less data for training the model, then our predictions will be less reliable.\n",
        "\n",
        "* If we use less data for testing the model, then the output of the model will be less reliable."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary library:\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Instantiating the model:\n",
        "model = LogisticRegression(fit_intercept=True, max_iter=10000)\n",
        "\n",
        "# Training the model:\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluating the model:\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "LFe8URBLouGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the coefficients:\n",
        "model.coef_"
      ],
      "metadata": {
        "id": "pxPgY3DbsJSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the  intercept value:\n",
        "model.intercept_"
      ],
      "metadata": {
        "id": "mcIephS3sYHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the predicted probabilities:\n",
        "train_preds = model.predict_proba(X_train)\n",
        "test_preds = model.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "N-sU6fkHscYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the predicted class:\n",
        "train_class_preds = model.predict(X_train)\n",
        "test_class_preds = model.predict(X_test)"
      ],
      "metadata": {
        "id": "8kRtVfbcsqwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary library for accuracy checking of the model:\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Getting accuracy score:\n",
        "train_accuracy = accuracy_score(train_class_preds,y_train)\n",
        "test_accuracy = accuracy_score(test_class_preds,y_test)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy)\n",
        "print(\"The accuracy on test data is \", test_accuracy)\n"
      ],
      "metadata": {
        "id": "Zqf56Dyss1tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary library for drawing confusion matrix:\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Defineing labels:\n",
        "labels = ['Not Happy', 'Neutral', 'Happy']\n",
        "\n",
        "cm = confusion_matrix(y_train, train_class_preds)\n",
        "\n",
        "# Ploting confusion matrix:\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
        "\n",
        "# Labels, title, and ticks:\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PDIeB9S-0MzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "# Defining the range of clusters to try:\n",
        "k_values = range(2, 11)\n",
        "\n",
        "# Initializing a list to store silhouette scores:\n",
        "silhouette_scores = []\n",
        "\n",
        "# Performing KMeans clustering and compute silhouette scores for each value of k:\n",
        "for k in k_values:\n",
        "    # Initializing KMeans model with explicit n_init value:\n",
        "    kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
        "\n",
        "    # Fiting KMeans model to the data:\n",
        "    kmeans.fit(new_restaurant_df)\n",
        "\n",
        "    # Computing silhouette score:\n",
        "    silhouette = silhouette_score(new_restaurant_df, kmeans.labels_)\n",
        "    silhouette_scores.append(silhouette)\n",
        "\n",
        "# Ploting silhouette scores:\n",
        "plt.plot(k_values, silhouette_scores, marker='o', label='Silhouette Score')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score vs. Number of Clusters')\n",
        "plt.xticks(k_values)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1\n",
        "#Importing necessary library for k-fold kmeans clustering:\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Defining the range of clusters to try:\n",
        "k_values = range(2, 11)\n",
        "\n",
        "# Initializing a list to store cross-validated scores:\n",
        "cv_scores = []\n",
        "\n",
        "# Performing cross-validation for each value of k:\n",
        "for k in k_values:\n",
        "    # Initializing KMeans model with explicit n_init value:\n",
        "    kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
        "\n",
        "    # Performing cross-validation:\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores = cross_val_score(kmeans, new_restaurant_df, cv=kf)\n",
        "    cv_scores.append(scores.mean())\n",
        "\n",
        "# Ploting cross-validated scores:\n",
        "plt.plot(k_values, cv_scores, marker='o', label='Cross-Validated Score')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Cross-Validated Score')\n",
        "plt.title('Cross-Validated Score vs. Number of Clusters')\n",
        "plt.xticks(k_values)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary library for calinski harabasz score:\n",
        "from sklearn.metrics import calinski_harabasz_score\n",
        "\n",
        "\n",
        "# Extracting all features from the DataFrame:\n",
        "X = new_restaurant_df.drop('Satisfied', axis=1)\n",
        "\n",
        "# Defining range of clusters to try:\n",
        "k_range = range(2, 11)\n",
        "\n",
        "# Initializing an empty list:\n",
        "ch_scores = []\n",
        "\n",
        "# Iterating over different numbers of clusters:\n",
        "for k in k_range:\n",
        "    # Performing K-means clustering:\n",
        "    kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
        "\n",
        "    kmeans.fit(X)\n",
        "\n",
        "    # Calculating the Calinski-Harabasz score:\n",
        "    ch_score = calinski_harabasz_score(X, kmeans.labels_)\n",
        "    ch_scores.append(ch_score)\n",
        "\n",
        "# Ploting the Calinski-Harabasz score for different numbers of clusters:\n",
        "plt.plot(k_range, ch_scores, marker='o')\n",
        "plt.title('Calinski-Harabasz Score vs. Number of Clusters')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Calinski-Harabasz Score')\n",
        "plt.xticks(k_range)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xKVRnk7QdScb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing an empty list:\n",
        "silhouette_scores = []\n",
        "\n",
        "# Iterating over different numbers of clusters:\n",
        "for k in k_range:\n",
        "    # Performing K-means clustering:\n",
        "    kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
        "    kmeans.fit(X) #Taking X from previous calinski harabasz score model:\n",
        "\n",
        "    # Calculating the silhouette score:\n",
        "    silhouette_avg = silhouette_score(X, kmeans.labels_)\n",
        "    silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# Ploting the silhouette scores for different numbers of clusters:\n",
        "plt.plot(k_range, silhouette_scores, marker='o')\n",
        "plt.title('Silhouette Score vs. Number of Clusters')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.xticks(k_range)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Z1bsEQOijAtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Answer Here:\n",
        "*These are key evaluation metrics to consider for a positive business impact:*\n",
        "* Rating\n",
        "* Cost\n",
        "* Setiment\n",
        "\n",
        "*These evaluation metrics help us understand the restaurant's service in relation to customer satisfaction. They allow us to gauge whether a customer is satisfied or not based on these metrics. If a restaurant provides excellent service and offers quality food for a fair price, customers are likely to give it a good rating, leading to a positive sentiment. A satisfied customer is a valuable asset for any company, as their satisfaction is crucial for growth. Therefore, it is essential to provide customers with high-quality food and services that justify the prices they are charged.*"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Observations and Suggestions:\n",
        "* Customers are willing to pay a higher amount for quality food and services. Zomato should encourage restaurants to provide better services and higher-quality food to customers.\n",
        "\n",
        "* Customers don't want low-quality food and services even at low costs. Zomato should encourage restaurants to increase the price and quality of their food.\n",
        "\n",
        "* Restaurants that charge between 800 and 1800 receive good ratings from customers, suggesting they provide quality food and services at a fair price. Zomato should recommend these restaurants to their customers.\n",
        "\n",
        "* Restaurants that charge less than 900 can become assets for Zomato if they improve their value-for-money food quality. Zomato should make efforts to facilitate this improvement.\n",
        "\n",
        "* The majority of reviewers prefer affordable restaurants, with some visiting the same restaurants multiple times. These restaurants likely offer good food at affordable prices. Zomato should recommend these restaurants to customers seeking affordable dining options, such as bachelors, college students, working professionals living alone, and others.\n",
        "\n",
        "* Some reviewers have left over 1000 reviews, indicating they are regular customers of Zomato's restaurant partners. Zomato should prioritize feedback from these customers.\n",
        "\n",
        "* There are reviewers with over 5000 followers, suggesting they may be bloggers or YouTubers. Zomato could offer these reviewers discounts to dine at their restaurant partners, thereby increasing the ratings and promoting these restaurants. It could prove to be a profitable partnership for Zomato.\n",
        "* Zomato has partnered with more than 4000 restaurants, and its estimated revenue has crossed 5 million. Zomato should maintain this pace if it wishes to be a market leader in this field."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}